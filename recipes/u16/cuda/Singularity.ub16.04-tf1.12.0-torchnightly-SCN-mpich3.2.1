#Bootstrap: docker
#From: DeepLearnPhysics/larcv2-singularity:ub16.04-tf1.12.0-torchnightly-mpich3.2.1

Bootstrap: localimage
From: /home/cadams/DeepLearnPhysics/larcv2-singularity/ub16.04-tf1.12.0-torchnightly


%help
Ubuntu16.04 with cuda9.0 cudnn7
ML/DL packages  : tensorflow keras torch sc-learn nccl
Sci.  packages  : numpy pandas sc-image matplotlib opencv-python
Basic python    : ipython jupyter yaml pygments six zmq wheel h5py tqdm mpi4py horovod
Development kit : g++/gcc cython nvcc libqt4-dev python-dev
Utility kit     : git wget emacs vim openssh-client mpich

To start your container simply try
singularity exec THIS_CONTAINER.simg bash

To use GPUs, try
singularity exec --nv THIS_CONTAINER.simg bash

%labels
Maintainer drinkingkazu cadams
Version ub16.04-tf1.12.0-torchnightly-mpich3.2.1

#------------
# Global installation
#------------
%environment

    # for MPICH:
    export PATH=/usr/local/mpich/install/bin/:${PATH}
    export LD_LIBRARY_PATH=/usr/local/mpich/install/lib/:${LD_LIBRARY_PATH}

%post

    apt-get -y install devscripts debhelper


    # nccl2
    git clone https://github.com/NVIDIA/nccl.git
    cd nccl;
    make -j src.build
    make pkg.debian.build
    dpkg -i build/pkg/deb/libnccl* 
    cd -

    
    # install MPICH
    wget -q http://www.mpich.org/static/downloads/3.2.1/mpich-3.2.1.tar.gz
    tar xf mpich-3.2.1.tar.gz
    rm mpich-3.2.1.tar.gz
    cd mpich-3.2.1
    # disable the addition of the RPATH to compiled executables
    # this allows us to override the MPI libraries to use those
    # found via LD_LIBRARY_PATH
    ./configure --prefix=/usr/local/mpich/install --disable-wrapper-rpath --disable-fortran
    make -j 4 install
    # add to local environment to build pi.c
    export PATH=$PATH:/usr/local/mpich//install/bin
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/mpich//install/lib
    env | sort
    cd ..
    rm -rf mpich-3.2.1
    
    
    # mpi and horovod
    pip --no-cache-dir --disable-pip-version-check install mpi4py

    # Workaround to build horovod without needing cuda libraries available:
    # temporary add stub drivers to ld.so.cache
    ldconfig /usr/local/cuda/lib64/stubs

    # install Horovod, add other HOROVOD_* environment variables as necessary
    HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_NCCL_HOME=/nccl/build/ pip install --no-cache-dir horovod

    # revert to standard libraries
    ldconfig
